import os
import random
from datetime import datetime
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# Modelo melhorado com instru√ß√µes
MODEL_NAME = "mistralai/Mistral-7B-Instruct-v0.1"

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)

# Carregar fil√≥sofos
with open("philosophers_list.txt", "r", encoding="utf-8") as f:
    philosophers = [line.strip() for line in f if line.strip()]

# Escolher fil√≥sofo do dia
today_index = datetime.now().toordinal() % len(philosophers)
philosopher = philosophers[today_index]

# Prompt mais limpo e espec√≠fico
prompt = f"""Responda apenas em portugu√™s. Escreva um par√°grafo objetivo e claro sobre o fil√≥sofo {philosopher}.
Inclua:
- Onde nasceu
- Quando viveu
- Principais ideias
- Sua obra mais famosa

N√£o repita palavras e n√£o inclua nenhum conte√∫do em ingl√™s. N√£o use listas. Escreva como se fosse um par√°grafo de uma revista de filosofia brasileira.
"""

# Gerar resposta
inputs = tokenizer(prompt, return_tensors="pt", truncation=True)
with torch.no_grad():
    outputs = model.generate(
        **inputs,
        max_new_tokens=400,
        temperature=0.7,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id
    )

generated = tokenizer.decode(outputs[0], skip_special_tokens=True)
article = generated.replace(prompt.strip(), "").strip()

# Corta se passar de 1900 caracteres (limite seguro para Discord)
article = article[:1900]

# Enviar no Discord
import discord
from discord.ext import commands

DISCORD_TOKEN = os.getenv("DISCORD_TOKEN")
CHANNEL_ID = int(os.getenv("CHANNEL_ID"))

intents = discord.Intents.default()
bot = commands.Bot(command_prefix="!", intents=intents)

@bot.event
async def on_ready():
    channel = bot.get_channel(CHANNEL_ID)
    if channel:
        await channel.send(f"üìö **{philosopher}**\n\n{article}")
    await bot.close()

bot.run(DISCORD_TOKEN)
